{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33624bb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.014630Z",
     "start_time": "2024-11-25T08:11:08.084656900Z"
    }
   },
   "outputs": [],
   "source": [
    "import chess \n",
    "import chess.pgn\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os \n",
    "import re \n",
    "\n",
    "# list each folder of folder \"games\"\n",
    "# get all folders\n",
    "folders = glob.glob(\"games/*\")\n",
    "\n",
    "# sort folders by date\n",
    "folders.sort(key=os.path.getmtime)\n",
    "\n",
    "df = pd.DataFrame(columns=[\"white\", \"black\", \"white_elo\", \"black_elo\", \"result\", \"nmoves\", \"nstarting_move\", \"pgn_base\", \"temperature\", \"random_engine\", \"has_illegal\", \"illegal_move\", \"folder_name\"])\n",
    "\n",
    "pgn_base_tab=[]\n",
    "\n",
    "def pgn_base_encode(txt):\n",
    "    if not (txt in pgn_base_tab):\n",
    "        pgn_base_tab.append(txt)\n",
    "    return pgn_base_tab.index(txt)\n",
    "\n",
    "for folder in folders:\n",
    "\n",
    "    # for each folder:\n",
    "    # read PGN file \"game.pgn\"\n",
    "\n",
    "    # check that \"game.pgn\" exists\n",
    "    if not os.path.exists(folder + \"/game.pgn\"):\n",
    "        print(\"No game.pgn in \" + folder) # TODO\n",
    "        continue\n",
    "    \n",
    "    with open(folder + \"/game.pgn\") as pgn:\n",
    "        game = chess.pgn.read_game(pgn)\n",
    "\n",
    "    # read metainformation.txt\n",
    "    # get the GPT model and the engine (SF or random)\n",
    "    nmove_value = None\n",
    "    with open(folder + \"/metainformation.txt\") as f:\n",
    "        lines = f.readlines()\n",
    "    # Iterate over each line in the file\n",
    "    for line in lines:\n",
    "        # Check if the line contains the string 'nmove:'\n",
    "        if 'nmove:' in line:\n",
    "            # Split the line at 'nmove:' and take the second part\n",
    "            # Then strip leading and trailing whitespaces and convert to integer\n",
    "            nmove_value = int(line.split('nmove:')[1].strip())\n",
    "            # Print the extracted value\n",
    "            break\n",
    "    \n",
    "    if nmove_value is None:\n",
    "        nmove_value = 1 # default value\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "    # number of moves\n",
    "    game_length = len(list(game.mainline_moves()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # for each PGN:\n",
    "    # get the GPT model and the engine (SF or random)\n",
    "    white = game.headers[\"White\"]\n",
    "    black = game.headers[\"Black\"]\n",
    "\n",
    "\n",
    "    # get the Elo of the engine (if any)\n",
    "\n",
    "    # get the Elo of the player (if any)\n",
    "    white_elo = game.headers[\"WhiteElo\"]\n",
    "    black_elo = game.headers[\"BlackElo\"]\n",
    "\n",
    "    # get the result (or infer based on checkmates) # special case: no mate, or unifinished game due to wrong move\n",
    "    result = game.headers[\"Result\"]\n",
    "\n",
    "    has_illegal = False\n",
    "    illegal_move = ''\n",
    "    # check that UnknownSAN key is in game\n",
    "    # if not, continue\n",
    "    if 'UnknownSAN' in game.headers:\n",
    "        has_illegal = True\n",
    "        illegal_move = game.headers[\"UnknownSAN\"]\n",
    "        #print(\"warning: UnknownSAN in game\")\n",
    "        # continue\n",
    "\n",
    "    with open(folder + \"/metainformation.txt\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # find the content between 'temperature:' and ends of line\n",
    "    match_random = re.search(r'random_engine:([\\s\\S]+?)(\\n)', content, re.MULTILINE)\n",
    "    random_engine = None\n",
    "    if match_random:\n",
    "        random_engine = match_random.group(1).strip()\n",
    "        if 'True' in random_engine:\n",
    "            random_engine = True\n",
    "        elif 'False' in random_engine:\n",
    "            random_engine = False\n",
    "        else:   \n",
    "            print(\"random engine value unclear/unknwon\")\n",
    "    else:\n",
    "        random_engine = False\n",
    "        # print('No random engine found') # default value: False (note: should not happen)\n",
    "\n",
    "    with open(folder + \"/metainformation.txt\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # find the content between 'temperature:' and ends of line\n",
    "    match_temperature = re.search(r'temperature:([\\s\\S]+?)(\\n)', content, re.MULTILINE)\n",
    "    temperature = None\n",
    "    if match_temperature:\n",
    "        temperature = match_temperature.group(1).strip()\n",
    "        # print(extracted_content)\n",
    "    else:\n",
    "        temperature = 0.0\n",
    "        # print('No temperature found') # default value: 0\n",
    "\n",
    "    with open(folder + \"/metainformation.txt\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Find the content between 'base_pgn:' and another term at the start of a new line followed by ':'\n",
    "    match = re.search(r'base_pgn:([\\s\\S]+?)(^\\w+:)', content, re.MULTILINE)\n",
    "    pgn_base = ''\n",
    "    if match:\n",
    "        # Extract and clean up the matched content\n",
    "        pgn_base = match.group(1).strip()\n",
    "        # print(extracted_content)\n",
    "    else:\n",
    "        print('No base pgn found')\n",
    "\n",
    "    # put in dfframe\n",
    "    # columns: white, black, white_elo, black_elo, result\n",
    "    # append to dfframe\n",
    "\n",
    "    df = df.append({\"white\": white, \"black\": black, \"white_elo\": white_elo, \"black_elo\": black_elo, \"result\": result, \"nmoves\" : game_length, \"nstarting_move\": nmove_value, \"pgn_base\" : pgn_base_encode(pgn_base), \"temperature\" : temperature, \"random_engine\" : random_engine, \"has_illegal\" : has_illegal, \"illegal_move\" : illegal_move, \"folder_name\" : folder}, ignore_index=True)\n",
    "\n",
    "\n",
    "    # compute stats\n",
    "    # scores in general, per Elo and chess engine, per GPT model\n",
    "    # ability to finish a game (with weaker models)\n",
    "\n",
    "    # first: Elo = 1700, GPT=3.5 instruct\n",
    "    # second: Elo = 1800, GPT=3.5 instruct\n",
    "    # ...\n",
    "\n",
    "print(pgn_base_tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee48e12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.100022800Z",
     "start_time": "2024-11-25T08:11:25.011393900Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Open and read the content of metainformation.txt\n",
    "with open(\"games/gamea7e73056-951a-417d-b671-0a60fba939f7/\" + 'metainformation.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Find the content between 'base_pgn:' and another term at the start of a new line followed by ':'\n",
    "match = re.search(r'base_pgn:([\\s\\S]+?)(^\\w+:)', content, re.MULTILINE)\n",
    "match = re.search(r'temperature:([\\s\\S]+?)(\\n)', content, re.MULTILINE)\n",
    "\n",
    "if match:\n",
    "    # Extract and clean up the matched content\n",
    "    extracted_content = match.group(1).strip()\n",
    "    print(extracted_content)\n",
    "else:\n",
    "    print('No match found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1b28bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.124966600Z",
     "start_time": "2024-11-25T08:11:25.028869600Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(df), \"games compiled in the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e66f75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.293460200Z",
     "start_time": "2024-11-25T08:11:25.042208800Z"
    }
   },
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.pgn\n",
    "import io \n",
    "\n",
    "\n",
    "# for column \"pgn_base\", I'd like to transform the string into a list of moves\n",
    "\n",
    "def pgn_to_list(pgn):\n",
    "    g = chess.pgn.read_game(io.StringIO(pgn))\n",
    "    g.mainline_moves()\n",
    "    return str(g.mainline_moves())\n",
    "\n",
    "def is_base_prompt(pgn):\n",
    "    g = chess.pgn.read_game(io.StringIO(pgn))\n",
    "    # [Event \"FIDE World Championship Match 2024\"]\\n[Site \"Los Angeles, USA\"]\n",
    "    return g.headers[\"Event\"] == \"FIDE World Championship Match 2024\" and g.headers[\"Site\"] == \"Los Angeles, USA\"\n",
    "\n",
    "def has_illegal_moves(pgn):\n",
    "    # exist g.headers[\"UnknownSAN\"] \n",
    "    g = chess.pgn.read_game(io.StringIO(pgn))\n",
    "    # key in array\n",
    "    return \"UnknownSAN\" in g.headers\n",
    "\n",
    "df[\"pgn_base_moves\"] = df[\"pgn_base\"].apply(pgn_to_list) # extract only moves\n",
    "df[\"base_pgn_prompt\"] = df[\"pgn_base\"].apply(is_base_prompt) # extract only prompt\n",
    "# df.sort_values(by=['nstarting_move'])\n",
    "df['temperature'] = pd.to_numeric(df['temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3118f825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.400863300Z",
     "start_time": "2024-11-25T08:11:25.297618200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Frequencies based on piece colors\n",
    "players = ['gpt-3.5-turbo-instruct', 'gpt-4', 'gpt-3.5-turbo', 'text-davinci-003']\n",
    "color_breakdown = {}\n",
    "for player in players:\n",
    "    white_count = df[df['white'] == player].shape[0]\n",
    "    black_count = df[df['black'] == player].shape[0]\n",
    "    color_breakdown[player] = {'white': white_count, 'black': black_count}\n",
    "\n",
    "for player in players:\n",
    "    nwhite = color_breakdown[player]['white']\n",
    "    nblack = color_breakdown[player]['black']\n",
    "    print(\" *\", player, \":\", nwhite+nblack, \"games, among\", nwhite, \"with white piece and\", nblack, \"with black pieces\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c098cd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.400863300Z",
     "start_time": "2024-11-25T08:11:25.327332500Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27a680b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.400863300Z",
     "start_time": "2024-11-25T08:11:25.373999400Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13b053b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.438199Z",
     "start_time": "2024-11-25T08:11:25.390588400Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"games_db.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28c35c6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.522087900Z",
     "start_time": "2024-11-25T08:11:25.427100600Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_score(df, model_name='gpt-3.5-turbo-instruct', percentage=True):\n",
    "    # Count the number of wins, losses, and draws for gpt-3.5-turbo-instruct\n",
    "    wins_as_white = df[(df['white'] == model_name) & (df['result'] == '1-0')].shape[0]\n",
    "    wins_as_black = df[(df['black'] == model_name) & (df['result'] == '0-1')].shape[0]\n",
    "    losses_as_white = df[(df['white'] == model_name) & (df['result'] == '0-1')].shape[0]\n",
    "    losses_as_black = df[(df['black'] == model_name) & (df['result'] == '1-0')].shape[0]\n",
    "    draws_as_white = df[(df['white'] == model_name) & (df['result'] == '1/2-1/2')].shape[0]\n",
    "    draws_as_black = df[(df['black'] == model_name) & (df['result'] == '1/2-1/2')].shape[0]\n",
    "\n",
    "    # Calculate total wins, losses, and draws\n",
    "    total_wins = wins_as_white + wins_as_black\n",
    "    total_losses = losses_as_white + losses_as_black\n",
    "    total_draws = draws_as_white + draws_as_black\n",
    "\n",
    "    if percentage:\n",
    "        return (total_wins + (total_draws * 0.5)) / (total_wins + total_losses + total_draws)\n",
    "    else:\n",
    "        return (total_wins + (total_draws * 0.5), total_wins + total_losses + total_draws)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d668c8a9",
   "metadata": {},
   "source": [
    "text-davinci-003 (completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08a9942",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.608216700Z",
     "start_time": "2024-11-25T08:11:25.438199Z"
    }
   },
   "outputs": [],
   "source": [
    "df_davinci = df.query(\"white == 'text-davinci-003' or black == 'text-davinci-003'\")\n",
    "print(len(df_davinci), \"games with davinci\")\n",
    "print(\"with white pieces\", len(df.query(\"white == 'text-davinci-003'\")))\n",
    "print(\"with black pieces\", len(df.query(\"black == 'text-davinci-003'\")))\n",
    "\n",
    "print(len(df_davinci.query(\"white == 'RANDOM chess engine' or black == 'RANDOM chess engine'\")), \"games against random chess engine\")\n",
    "# print(compute_score(df_davinci.query(\"white == 'RANDOM chess engine' or black == 'RANDOM chess engine'\"), \"text-davinci-003\"))\n",
    "\n",
    "\n",
    "print(len(df_davinci.query(\"has_illegal == True\")), \"games with illegal move\")\n",
    "print(\"score\", compute_score(df_davinci, \"text-davinci-003\"))\n",
    "\n",
    "print(\"the only game with no illegal move is\")\n",
    "df_davinci.query(\"has_illegal == False\")\n",
    "\n",
    "\n",
    "# box plot of df_davinci['nmoves']\n",
    "print(\"The longest game was\", df_davinci['nmoves'].max()/2, \"moves\")\n",
    "print(\"The shortest game was\", df_davinci['nmoves'].min()/2, \"moves\")\n",
    "print(\"The average game length was\", df_davinci['nmoves'].mean()/2, \"moves\")\n",
    "print(\"The median game length was\", df_davinci['nmoves'].median()/2, \"moves\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eed048b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.640078100Z",
     "start_time": "2024-11-25T08:11:25.469274400Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f965e556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.655816400Z",
     "start_time": "2024-11-25T08:11:25.487696900Z"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=['pgn_base'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2edd56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.655816400Z",
     "start_time": "2024-11-25T08:11:25.517984300Z"
    }
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=['white_elo'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7ff6806",
   "metadata": {},
   "source": [
    "GPTs against random engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38750b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:25.914757700Z",
     "start_time": "2024-11-25T08:11:25.550059100Z"
    }
   },
   "outputs": [],
   "source": [
    "df_random = df.query(\"random_engine == True\")\n",
    "df_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48693dae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:26.329391600Z",
     "start_time": "2024-11-25T08:11:25.577516600Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt35_instruct_legal_games = df_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct') and has_illegal == False\")\n",
    "score35 = compute_score(gpt35_instruct_legal_games, model_name='gpt-3.5-turbo-instruct') #['illegal_move'].value_counts()\n",
    "print(\"Score\", round(100*score35, 2), \"% for games with only legal moves\")\n",
    "\n",
    "score, t = compute_score(gpt35_instruct_legal_games, model_name='gpt-3.5-turbo-instruct', percentage=False)\n",
    "print(\"Score\", score, \" for games with only legal moves (\", t, \"games)\")\n",
    "\n",
    "print(\"The only not won game is:\", \"https://lichess.org/bE99x52y\", \"is due to repetition\")\n",
    "\n",
    "vals35 = df_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct')\")['has_illegal'].value_counts()\n",
    "print(vals35[0], \"legal games and\", vals35[1], \"illegal games\", \"(out of\", vals35[0] + vals35[1], \"total games)\")\n",
    "\n",
    "print(\"Illegal moves are\", df_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct')\")['illegal_move'].value_counts())\n",
    "\n",
    "print(\"Number of moves against random chess engine\")\n",
    "print(\"The longest game was\", gpt35_instruct_legal_games['nmoves'].max()/2, \"moves\")\n",
    "print(\"The shortest game was\", gpt35_instruct_legal_games['nmoves'].min()/2, \"moves\")\n",
    "print(\"The average game length was\", gpt35_instruct_legal_games['nmoves'].mean()/2, \"moves\")\n",
    "print(\"The median game length was\", gpt35_instruct_legal_games['nmoves'].median()/2, \"moves\")\n",
    "\n",
    "print(gpt35_instruct_legal_games.sort_values(by=\"nmoves\", ascending=True)['folder_name'])\n",
    "\n",
    "(gpt35_instruct_legal_games['nmoves'] / 2).plot(kind='box')\n",
    "\n",
    "\n",
    "#### same for gpt-3.5-turbo \n",
    "gpt35_legal_games = df_random.query(\"(white == 'gpt-3.5-turbo' or black == 'gpt-3.5-turbo') and has_illegal == False\")\n",
    "score35 = compute_score(gpt35_legal_games, model_name='gpt-3.5-turbo') #['illegal_move'].value_counts()\n",
    "print(\"Score\", round(100*score35, 2), \"% for games with only legal moves\")\n",
    "\n",
    "vals35 = df_random.query(\"(white == 'gpt-3.5-turbo' or black == 'gpt-3.5-turbo')\")['has_illegal'].value_counts()\n",
    "print(vals35[0], \"legal games and\", vals35[1], \"illegal games\", \"(out of\", vals35[0] + vals35[1], \"total games)\")\n",
    "\n",
    "print(\"Illegal moves are\", df_random.query(\"(white == 'gpt-3.5-turbo' or black == 'gpt-3.5-turbo')\")['illegal_move'].value_counts())\n",
    "print(\"Quite severe example:\", \"https://lichess.org/FMoHsC7m\", \"with Bxd6\") # gameb5a17c54-fc9b-4a55-867b-ca61800ba228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eee201",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:26.447925900Z",
     "start_time": "2024-11-25T08:11:26.045572900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_non_random = df.query(\"random_engine == False and nstarting_move <= 2\")\n",
    "\n",
    "def analyze_model_performance(df_m, model_gpt_name):    \n",
    "\n",
    "    print(f\"Analysis against SF (no random engine, no random first moves) for model: {model_gpt_name}\")\n",
    "\n",
    "    model_games = df_m.query(f\"(white == '{model_gpt_name}' or black == '{model_gpt_name}') and has_illegal == False\")\n",
    "    score_model = compute_score(model_games, model_name=model_gpt_name)\n",
    "    print(\"Score\", round(100*score_model, 2), \"% for games with only legal moves\")\n",
    "    score, t = compute_score(model_games, model_name=model_gpt_name, percentage=False)\n",
    "    print(\"Score\", score, \"for games with only legal moves (\", t, \"games)\")\n",
    "\n",
    "    tot = len(df_m.query(f\"(white == '{model_gpt_name}' or black == '{model_gpt_name}')\"))\n",
    "    print(\"Score\", round(100*(score/tot), 2), \"% for all games, being legal or illegal\")\n",
    "    print(\"Score\", score, \"for all games (\", tot, \"games)\")\n",
    "\n",
    "    vals_model = df_m.query(f\"(white == '{model_gpt_name}' or black == '{model_gpt_name}')\")['has_illegal'].value_counts()\n",
    "    ntot = vals_model.get(0, 0) + vals_model.get(1, 0)\n",
    "\n",
    "    print(\"Out of\", ntot ,\"games against SF,\", vals_model.get(0, 0), \"were legal games and\", vals_model.get(1, 0), \"were illegal games, hence\", round((vals_model.get(1, 0)/ntot)*100), \"% of illegal games.\")\n",
    "    print(vals_model.get(0, 0), \"legal games and\", vals_model.get(1, 0), \"illegal games\", \"(out of\", ntot, \"total games)\")\n",
    "    print(round((vals_model.get(1, 0)/ntot)*100), \"% of illegal games\")\n",
    "\n",
    "    print(\"Illegal moves are:\")\n",
    "    print(df_m.query(f\"(white == '{model_gpt_name}' or black == '{model_gpt_name}') and has_illegal == True\")['illegal_move'].value_counts().to_markdown())\n",
    "\n",
    "    print(\"Illegal moves with n first random move are:\")\n",
    "    print(df_m.query(f\"(white == '{model_gpt_name}' or black == '{model_gpt_name}') and has_illegal == True and nstarting_move > 2\")['illegal_move'].value_counts().to_markdown())\n",
    "\n",
    "# Example usage:\n",
    "# analyze_model_performance(df_non_random, 'gpt-3.5-turbo-instruct')\n",
    "# analyze_model_performance(df_non_random, 'gpt-4')\n",
    "\n",
    "# analyze_model_performance(df_random, 'gpt-4')\n",
    "\n",
    "analyze_model_performance(df_random, 'gpt-3.5-turbo')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb299e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:26.500947100Z",
     "start_time": "2024-11-25T08:11:26.100443700Z"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_model_performance(df, gpt_model_name):\n",
    "    df_non_random_with_random_first_moves = df.query(\"random_engine == False and nstarting_move > 2\")\n",
    "\n",
    "    print(f\"Analysis against SF (no random engine, random first moves) for {gpt_model_name}\")\n",
    "\n",
    "    gpt_instruct_legal_games_with_random_first_moves = df_non_random_with_random_first_moves.query(f\"(white == '{gpt_model_name}' or black == '{gpt_model_name}') and has_illegal == False\")\n",
    "    score = compute_score(gpt_instruct_legal_games_with_random_first_moves, model_name=gpt_model_name)\n",
    "    print(f\"Score {round(100*score, 2)}% for games with only legal moves\")\n",
    "    \n",
    "    score, t = compute_score(gpt_instruct_legal_games_with_random_first_moves, model_name=gpt_model_name, percentage=False)\n",
    "    print(f\"Score {score} for games with only legal moves ({t} games)\")\n",
    "\n",
    "    tot = len(df_non_random_with_random_first_moves.query(f\"(white == '{gpt_model_name}' or black == '{gpt_model_name}')\"))\n",
    "    print(f\"Score {round(100*(score/tot), 2)}% for all games, being legal or illegal\")\n",
    "    print(f\"Score {score} for all games ({tot} games)\")\n",
    "\n",
    "    vals = df_non_random_with_random_first_moves.query(f\"(white == '{gpt_model_name}' or black == '{gpt_model_name}')\")['has_illegal'].value_counts()\n",
    "    ntot = vals.get(0, 0) + vals.get(1, 0)\n",
    "    illegal_percentage = round((vals.get(1, 0)/ntot)*100) if ntot else 0\n",
    "\n",
    "    print(f\"Out of {ntot} games against SF, {vals.get(0, 0)} were legal games and {vals.get(1, 0)} were illegal games, hence {illegal_percentage}% of illegal games.\")\n",
    "    print(f\"{vals.get(0, 0)} legal games and {vals.get(1, 0)} illegal games (out of {ntot} total games)\")\n",
    "    print(f\"{illegal_percentage}% of illegal games\")\n",
    "\n",
    "    print(\"Illegal moves are:\")\n",
    "    print(df_non_random_with_random_first_moves.query(f\"(white == '{gpt_model_name}' or black == '{gpt_model_name}') and has_illegal == True\")['illegal_move'].value_counts().to_markdown())\n",
    "\n",
    "    print(f\"Illegal moves with n first random move are:\")\n",
    "    print(df_non_random_with_random_first_moves.query(f\"(white == '{gpt_model_name}' or black == '{gpt_model_name}') and has_illegal == True and nstarting_move > 2\")['illegal_move'].value_counts().to_markdown())\n",
    "\n",
    "# Example usage:\n",
    "analyze_model_performance(df, 'gpt-3.5-turbo-instruct')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e5b8c4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:26.500947100Z",
     "start_time": "2024-11-25T08:11:26.148937700Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a4a2b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:26.544972Z",
     "start_time": "2024-11-25T08:11:26.168365500Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct')\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8aafa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:26.548835400Z",
     "start_time": "2024-11-25T08:11:26.182091300Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_moves_and_illegals(df_l, gpt_model_name):\n",
    "    illegal_white_moves = len(df_l.query(f\"(white == '{gpt_model_name}') and has_illegal == True\"))\n",
    "    total_white_moves = len(df_l.query(f\"(white == '{gpt_model_name}')\"))\n",
    "    total_black_moves = len(df_l.query(f\"(black == '{gpt_model_name}')\"))\n",
    "    illegal_black_moves = len(df_l.query(f\"(black == '{gpt_model_name}') and has_illegal == True\"))\n",
    "\n",
    "    print(illegal_white_moves, \"illegal moves with white\")\n",
    "    print(total_white_moves)\n",
    "    print(total_black_moves)\n",
    "    print(illegal_black_moves, \"illegal moves with black\")\n",
    "\n",
    "    return illegal_white_moves, total_white_moves, total_black_moves, illegal_black_moves\n",
    "\n",
    "# count_moves_and_illegals(df_non_random, 'gpt-3.5-turbo-instruct')\n",
    "count_moves_and_illegals(df_non_random, 'gpt-4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b3ffaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:26.548835400Z",
     "start_time": "2024-11-25T08:11:26.214520600Z"
    }
   },
   "outputs": [],
   "source": [
    "mask = (df_non_random[\"white\"] == 'gpt-3.5-turbo-instruct') | (df_non_random[\"black\"] == 'gpt-3.5-turbo-instruct')\n",
    "illegal_gpt35vsSF_instruct = df_non_random.loc[mask & (df_non_random[\"has_illegal\"] == True)].copy()\n",
    "illegal_gpt35vsSF_instruct[\"temperature\"] = illegal_gpt35vsSF_instruct[\"temperature\"].astype(float)\n",
    "\n",
    "print(illegal_gpt35vsSF_instruct[[\"temperature\"]].value_counts())\n",
    "\n",
    "t8 = len(df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct') and `temperature` == '0.8'\")) / len(df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct')\"))\n",
    "print(round(100*t8, 2), \"% of games with temperature 0.8\")\n",
    "\n",
    "print(df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct') and `temperature` == '0.8' and has_illegal == True\")['illegal_move'].value_counts().to_markdown())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8fe079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:26.548835400Z",
     "start_time": "2024-11-25T08:11:26.244991800Z"
    }
   },
   "outputs": [],
   "source": [
    "illegal_gpt35vsSF_instruct = df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct') and has_illegal == True\") # [['pgn_base']].value_counts()\n",
    "n = 0\n",
    "m = 0\n",
    "for i, row in illegal_gpt35vsSF_instruct.iterrows():\n",
    "    if \"Rennes FRA\" in row[\"pgn_base\"]:\n",
    "        n = n + 1\n",
    "    else:\n",
    "        m = m + 1\n",
    "\n",
    "print(len(df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct') and pgn_base.str.contains('Rennes FRA')\")), \"games with altered prompt\")\n",
    "print(len(df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct') and pgn_base.str.contains('Rennes FRA')\")) / len(df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct')\")) * 100, \"% games with altered prompt\")\n",
    "\n",
    "print(n, \"illegal games with altered prompts and\", m, \"illegal games with original prompts\")\n",
    "print(illegal_gpt35vsSF_instruct.query(\"pgn_base.str.contains('Rennes FRA')\")['illegal_move'].value_counts())\n",
    "\n",
    "print(df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct') and has_illegal == True\")['nstarting_move'].value_counts().to_markdown())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ee51b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:26.606745Z",
     "start_time": "2024-11-25T08:11:26.279434900Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Does random first moves impact?\")\n",
    "print(df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct')\")['nstarting_move'].value_counts().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c63170",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:26.606745Z",
     "start_time": "2024-11-25T08:11:26.289533500Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_invalid_games(df_l, model_gpt_name):\n",
    "    query_str = f\"(white == '{model_gpt_name}' or black == '{model_gpt_name}') and has_illegal == True and illegal_move != '1-0' and illegal_move != '1-'\"\n",
    "    \n",
    "    x = 0\n",
    "    for _, r in df_l.query(query_str).iterrows():\n",
    "        if '=' in r['illegal_move'] or '{' in r['illegal_move']:\n",
    "            continue\n",
    "\n",
    "        print(r['illegal_move'], r['folder_name'])\n",
    "        x += 1 \n",
    "\n",
    "    percentage = round(x / len(df_l.query(f\"(white == '{model_gpt_name}' or black == '{model_gpt_name}')\")), 3) * 100\n",
    "    print(f'If we consider \"1-0\", \"comments\", and \"unspecified promotions\" as fixable, then {percentage} % are non valid games')\n",
    "\n",
    "    return percentage\n",
    "\n",
    "count_invalid_games(df_non_random, 'gpt-3.5-turbo-instruct')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5d116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T08:11:27.348034600Z",
     "start_time": "2024-11-25T08:11:26.329391600Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Qualitative analysis of illegal moves:\")\n",
    "\n",
    "import pandas as pd\n",
    "from stockfish import Stockfish\n",
    "\n",
    "# A list to store your data\n",
    "data_list = []\n",
    "\n",
    "illegal_moves10 = df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct') and illegal_move == '1-0'\")\n",
    "\n",
    "for index, row in illegal_moves10.iterrows():\n",
    "    if row['white'] == 'gpt-3.5-turbo-instruct':\n",
    "        color = \"White\"\n",
    "    else:\n",
    "        color = \"Black\"\n",
    "\n",
    "    # read the PGN file\n",
    "    with open(row['folder_name'] + \"/game.pgn\") as pgn:\n",
    "        game = chess.pgn.read_game(pgn)\n",
    "        board = game.board()\n",
    "        for move in game.mainline_moves():\n",
    "            board.push(move)\n",
    "\n",
    "        stockfish = Stockfish(\"./stockfish/stockfish-ubuntu-x86-64-avx2\")\n",
    "        stockfish.set_position([str(m) for m in game.mainline_moves()])\n",
    "        # stockfish._go_time(5000)\n",
    "        ev = stockfish.get_evaluation()\n",
    "\n",
    "        # Create an evaluation string\n",
    "        if ev['type'] == 'cp':\n",
    "            evaluation = str(ev['value']/100)\n",
    "        else:\n",
    "            evaluation = \"Mate in \" + str(ev['value'])\n",
    "\n",
    "        # Append the dictionary to your list\n",
    "        data_list.append({\n",
    "            \"GPT Color\": color,\n",
    "            \"Assessment\": evaluation\n",
    "        })\n",
    "\n",
    "# Convert the list of dictionaries into a dataframe\n",
    "df_results = pd.DataFrame(data_list)\n",
    "\n",
    "# If you want to see the first few rows of your dataframe:\n",
    "print(df_results.to_markdown())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7509c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.238982800Z"
    }
   },
   "outputs": [],
   "source": [
    "df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct' and has_illegal == True)\").sort_values(by=\"nmoves\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb15fb4a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.238982800Z"
    }
   },
   "outputs": [],
   "source": [
    "j = 0\n",
    "cp_g = 0\n",
    "for index, row in df_results.iterrows():\n",
    "    if 'Mate' in row['Assessment']:\n",
    "        j = j + 1\n",
    "    elif float(row['Assessment']) > 5.0:\n",
    "        cp_g = cp_g + 1\n",
    "\n",
    "print(j, \"games with mate\", \"out of\", len(df_results), \"games\")\n",
    "print(cp_g, \"games with cp > 5.0\", \"out of\", len(df_results), \"games\")\n",
    "print(len(df_results) - (j+cp_g), \"games with cp < 5.0\", \"out of\", len(df_results), \"games\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4c710",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.238982800Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_games(df_l, model_name):\n",
    "    # Query for games played by the given model\n",
    "    model_games = df_l.query(f\"(white == '{model_name}' or black == '{model_name}')\")\n",
    "    model_games['nmoves'] = model_games['nmoves'] / 2\n",
    "    \n",
    "    # Sum of moves played by the model\n",
    "    white_nmoves = df_l.query(f\"white == '{model_name}'\")['nmoves'].sum() / 2\n",
    "    black_nmoves = df_l.query(f\"black == '{model_name}'\")['nmoves'].sum() / 2\n",
    "    t_moves = model_games['nmoves'].sum()\n",
    "\n",
    "    # Count of illegal moves\n",
    "    illegal_moves = len(df_l.query(f\"(white == '{model_name}' or black == '{model_name}') and has_illegal == True\"))\n",
    "    illegal_moves_10 = len(df_l.query(f\"(white == '{model_name}' or black == '{model_name}') and has_illegal == True and illegal_move != '1-0'\"))\n",
    "\n",
    "    # Printing results\n",
    "    print(\"illegal moves\", round(illegal_moves/t_moves, 5)*100, \"%\")\n",
    "    print(\"illegal_moves without 1-0:\", round(illegal_moves_10/t_moves, 5)*100, \"%\")\n",
    "    print(\"Total number of moves played by\", model_name, \":\", t_moves)\n",
    "    print(\"White played\", white_nmoves, \"moves\")\n",
    "    print(\"Black played\", black_nmoves, \"moves\")\n",
    "    print(\"Number of moves against SF\")\n",
    "    print(\"The longest game was\", model_games['nmoves'].max(), \"moves\")\n",
    "    print(\"The shortest game was\", model_games['nmoves'].min(), \"moves\")\n",
    "    print(\"The average game length was\", model_games['nmoves'].mean(), \"moves\")\n",
    "    print(\"The median game length was\", model_games['nmoves'].median(), \"moves\")\n",
    "\n",
    "    # Plotting box plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(model_games['nmoves'])\n",
    "    plt.title(f\"Number of moves per game against SF\")\n",
    "    plt.ylabel(\"Number of moves\")\n",
    "    plt.xlabel(f\"{model_name}\")\n",
    "    plt.savefig(f\"{model_name}_games_nmoves.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# analyze_games(df_non_random, 'gpt-3.5-turbo-instruct')\n",
    "analyze_games(df_non_random, 'gpt-4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acae5ba",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.250953Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#### same for gpt-3.5-turbo\n",
    "gpt35_legal_games = df_non_random.query(\"(white == 'gpt-3.5-turbo' or black == 'gpt-3.5-turbo') and has_illegal == False\")\n",
    "score35 = compute_score(gpt35_legal_games, model_name='gpt-3.5-turbo') #['illegal_move'].value_counts()\n",
    "print(\"Score\", round(100*score35, 2), \"% for games with only legal moves\")\n",
    "\n",
    "vals35 = df_non_random.query(\"(white == 'gpt-3.5-turbo' or black == 'gpt-3.5-turbo')\")['has_illegal'].value_counts()\n",
    "print(vals35[0], \"legal games and\", vals35[1], \"illegal games\", \"(out of\", vals35[0] + vals35[1], \"total games)\")\n",
    "\n",
    "print(\"Illegal moves are\", df_non_random.query(\"(white == 'gpt-3.5-turbo' or black == 'gpt-3.5-turbo')\")['illegal_move'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be0777",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.254529600Z"
    }
   },
   "outputs": [],
   "source": [
    "df_gpt35 = df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct')\")\n",
    "print(len(df_gpt35), \"games played against SF\")\n",
    "print(len(df_gpt35.query(\"has_illegal == False\")), \"legal games played against SF\")\n",
    "\n",
    "# Extracting elo values for games where Stockfish is playing against gpt-3.5-turbo-instruct\n",
    "stockfish_black_elo_vs_gpt3_5_instruct = df_gpt35['black_elo']\n",
    "# remove values with '?' value\n",
    "stockfish_black_elo_vs_gpt3_5_instruct = stockfish_black_elo_vs_gpt3_5_instruct[stockfish_black_elo_vs_gpt3_5_instruct != '?']\n",
    "\n",
    "stockfish_white_elo_vs_gpt3_5_instruct = df_gpt35['white_elo']\n",
    "# remove values with '?' value\n",
    "stockfish_white_elo_vs_gpt3_5_instruct = stockfish_white_elo_vs_gpt3_5_instruct[stockfish_white_elo_vs_gpt3_5_instruct != '?']\n",
    "\n",
    "\n",
    "# Combining Elo ratings of Stockfish as both white and black player\n",
    "combined_stockfish_elo = pd.concat([stockfish_white_elo_vs_gpt3_5_instruct, stockfish_black_elo_vs_gpt3_5_instruct])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have already computed value counts\n",
    "value_counts = combined_stockfish_elo.value_counts().sort_index()\n",
    "\n",
    "# Plotting the histogram for combined Elo ratings\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(value_counts.index, value_counts.values)\n",
    "plt.xlabel('Elo rating')\n",
    "plt.ylabel('Number of games')\n",
    "plt.title('Elo rating distribution of Stockfish for games of gpt-3.5-turbo-instruct against Stockfish')\n",
    "plt.savefig(\"stockfish_elo_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621c14c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.254529600Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt4_legal_games = df_random.query(\"(white == 'gpt-4' or black == 'gpt-4') and has_illegal == False\")\n",
    "score4 = compute_score(gpt4_legal_games, model_name='gpt-4') #['illegal_move'].value_counts()\n",
    "print(\"Score\", round(100*score4, 2), \"% for games with only legal moves\")\n",
    "\n",
    "print(\"The only not won game is:\", \"https://lichess.org/1A1IrIjO#74\", \"leads to stalemate in a completely winning position\")\n",
    "\n",
    "vals4 = df_random.query(\"(white == 'gpt-4' or black == 'gpt-4')\")['has_illegal'].value_counts()\n",
    "print(vals4[0], \"legal games and\", vals4[1], \"illegal games\", \"(out of\", vals4[0] + vals4[1], \"total games)\")\n",
    "\n",
    "print(\"Illegal moves are\", df_random.query(\"(white == 'gpt-4' or black == 'gpt-4')\")['illegal_move'].value_counts())\n",
    "print(\"Illegal moves are much more severe here! ie they are really illegal moves\", \"see eg https://lichess.org/k2MhW32K or https://lichess.org/lVIF2hvE#48\")\n",
    "print(\"This https://lichess.org/wFwTWWgh is more about ambigous move\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93722364",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.254529600Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the style of seaborn for better visualization\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "def plot_histogram(df):\n",
    "    # Initialize the matplotlib figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot histogram of nmoves\n",
    "    sns.histplot(df['nmoves'], bins=30, kde=True, color=\"skyblue\")\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.xlabel('Number of Moves', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "    plt.title('Distribution of Number of Moves in Chess Games', fontsize=16)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "def plot_boxplot(df):\n",
    "    # Initialize the matplotlib figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Create a boxplot of nmoves\n",
    "    sns.boxplot(x=df['nmoves'], color=\"lightblue\")\n",
    "\n",
    "    # Set plot labels and title\n",
    "    plt.xlabel('Number of Moves', fontsize=14)\n",
    "    plt.title('Boxplot of Number of Moves in Chess Games', fontsize=16)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f1abd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.254529600Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_histogram(gpt4_legal_games)\n",
    "plot_boxplot(gpt4_legal_games)\n",
    "plot_histogram(gpt35_instruct_legal_games)\n",
    "plot_boxplot(gpt35_instruct_legal_games)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92f1f217",
   "metadata": {},
   "source": [
    "GPT4 is weaker than GPT35 instruct for legal moves\n",
    "Yet GPT4 and GPT35 instruct are capable of winning a significant number of games (99%) when legal moves are played all along. \n",
    "GPT4 and GPT35 can play quite long games (resp. 28 moves and 35 moves on average)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1701256",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.254529600Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_random.query(\"(white == 'gpt-4' or black == 'gpt-4') and has_illegal == False\")\n",
    "df_random['white'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549abf5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.254529600Z"
    }
   },
   "outputs": [],
   "source": [
    "df_random.query(\"white == 'gpt-4' or black == 'gpt-4'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ace2bf9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.266558700Z"
    }
   },
   "outputs": [],
   "source": [
    "df_random.query(\"white != 'gpt-4' and black != 'gpt-4'\").has_illegal.value_counts(), df_random.query(\"white == 'gpt-4' or black == 'gpt-4'\").has_illegal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a575c38f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.266558700Z"
    }
   },
   "outputs": [],
   "source": [
    "df_random.query(\"white != 'gpt-4' and black != 'gpt-4' and has_illegal == True\")\n",
    "df_random.query(\"white == 'gpt-3.5-turbo' or black == 'gpt-3.5-turbo'\")\n",
    "df_random.query(\"(white == 'gpt-4' or black == 'gpt-4') and has_illegal == True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8715692d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.270600600Z"
    }
   },
   "outputs": [],
   "source": [
    "compute_score(df_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7445721",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.271109100Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.query(\"random_engine == False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40acc82",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.274611800Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a2b46",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.277340500Z"
    }
   },
   "outputs": [],
   "source": [
    "df['temperature'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0a104c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.279608900Z"
    }
   },
   "outputs": [],
   "source": [
    "df.query('nstarting_move <= 2 and temperature == 0.0') # right now nmoves with 1 corresponds to traditional stuff... with 2 corresponds to basic, well-known, random openings and is fair... n > 2 corresponds to k random moves (and is a bit unfair for either side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a044c8e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.281143300Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c2f9d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.282656800Z"
    }
   },
   "outputs": [],
   "source": [
    "df.query('nstarting_move <= 2 and temperature == 0.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3073946e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.284194700Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9da2c3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.284194700Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_histogram(df)\n",
    "plot_histogram(df.query('nstarting_move > 2'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c60a6e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.284194700Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_boxplot(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1215102",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.288702200Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_average(df, model_name='gpt-3.5-turbo-instruct'):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Convert Elo columns to numeric, setting errors='coerce' to handle non-numeric values\n",
    "    df_copy['white_elo'] = pd.to_numeric(df_copy['white_elo'], errors='coerce')\n",
    "    df_copy['black_elo'] = pd.to_numeric(df_copy['black_elo'], errors='coerce')\n",
    "\n",
    "    # Filter out rows where gpt-3.5-turbo-instruct is the player and get the opponent's Elo\n",
    "    opponent_elo_white = df_copy[df_copy['white'] == model_name]['black_elo']\n",
    "    opponent_elo_black = df_copy[df_copy['black'] == model_name]['white_elo']\n",
    "\n",
    "    # Concatenate the Elo ratings of opponents when gpt-3.5-turbo-instruct played as white and black\n",
    "    all_opponent_elo = pd.concat([opponent_elo_white, opponent_elo_black])\n",
    "\n",
    "    # Calculate the average Elo rating of the opponents, excluding missing or NaN values\n",
    "    average_opponent_elo = all_opponent_elo.mean()\n",
    "\n",
    "    return average_opponent_elo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff0c1e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.290364100Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import fsolve\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def computation_Elo(df,  initial_guess = 1700, model_name='gpt-3.5-turbo-instruct', K=400):\n",
    "    # Given values\n",
    "    S_A = compute_score(df, model_name)  # The score of Player A\n",
    "    R_B = compute_average(df, model_name)  # The rating of Player \n",
    "\n",
    "    # Define the equation to solve for R_A\n",
    "    def equation(R_A, *data):\n",
    "        S_A, R_B = data\n",
    "        return S_A - 1 / (1 + 10**((R_B - R_A) / K)) \n",
    "\n",
    "    # Solve the equation for R_A\n",
    "    R_A_solution = fsolve(equation, initial_guess, args=(S_A, R_B))\n",
    "\n",
    "    # Extract the calculated R_A value\n",
    "    R_A_calculated = float(R_A_solution[0])\n",
    "    return R_A_calculated\n",
    "\n",
    "computation_Elo(df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct')\")), computation_Elo(df.query('nstarting_move <= 2 and temperature == 0.0')), computation_Elo(df.query('nstarting_move <= 2 and temperature == 0.8')), computation_Elo(df.query('nstarting_move > 2 and temperature == 0.0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec0f29",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.290364100Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# rs = []\n",
    "# for i in range(0, 1000):\n",
    "#     rs.append(compute_elo(df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct') and `has_illegal` == False\").sample(), candidate_name=\"gpt-3.5-turbo-instruct\", starting_elo=1500, K=400))\n",
    "\n",
    "\n",
    "def lookup_fide_table(score):\n",
    "        # Data here: https://handbook.fide.com/chapter/B022017\n",
    "        data = {\n",
    "            'p': [1.0, .99, .98, .97, .96, .95, .94, .93, .92, .91, .90, .89, .88, .87, .86, .85, .84,\n",
    "                .83, .82, .81, .80, .79, .78, .77, .76, .75, .74, .73, .72, .71, .70, .69, .68, .67,\n",
    "                .66, .65, .64, .63, .62, .61, .60, .59, .58, .57, .56, .55, .54, .53, .52, .51, .50,\n",
    "                .49, .48, .47, .46, .45, .44, .43, .42, .41, .40, .39, .38, .37, .36, .35, .34, .33,\n",
    "                .32, .31, .30, .29, .28, .27, .26, .25, .24, .23, .22, .21, .20, .19, .18, .17, .16,\n",
    "                .15, .14, .13, .12, .11, .10, .09, .08, .07, .06, .05, .04, .03, .02, .01],\n",
    "            'dp': [800, 677, 589, 538, 501, 470, 444, 422, 401, 383, 366, 351, 336, 322, 309, 296, 284,\n",
    "                273, 262, 251, 240, 230, 220, 211, 202, 193, 184, 175, 166, 158, 149, 141, 133, 125,\n",
    "                117, 110, 102, 95, 87, 80, 72, 65, 57, 50, 43, 36, 29, 21, 14, 7, 0, -7, -14, -21, \n",
    "                -29, -36, -43, -50, -57, -65, -72, -80, -87, -95, -102, -110, -117, -125, -133, -141,\n",
    "                -149, -158, -166, -175, -184, -193, -202, -211, -220, -230, -240, -251, -262, -273, \n",
    "                -284, -296, -309, -322, -336, -351, -366, -383, -401, -444, -470, -501, -538, -589, -677, -800]\n",
    "        }\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df_fide = pd.DataFrame(data)\n",
    "\n",
    "        rscore = round(score, 2)\n",
    "\n",
    "        # lookup score in table\n",
    "        dp = df_fide.loc[df_fide['p'] == rscore, 'dp'].iloc[0]\n",
    "        return dp\n",
    "\n",
    "def fide_elo_computation(dfe, model_name, score=None):\n",
    "    average_opponents_ratings = compute_average(dfe, model_name)\n",
    "    if score is None:\n",
    "        score = compute_score(dfe, model_name)\n",
    "    dp = lookup_fide_table(score)\n",
    "\n",
    "\n",
    "    return average_opponents_ratings + dp\n",
    "\n",
    "                    \n",
    "def compute_elo(df_l, model_gpt_name):\n",
    "    df_elo = df_l.query(f\"(white == '{model_gpt_name}' or black == '{model_gpt_name}') and `has_illegal` == False\")\n",
    "    fide_elo_value = round(fide_elo_computation(df_elo, model_gpt_name), 0)\n",
    "    print(f\"{fide_elo_value} Elo for {model_gpt_name} against SF and only with legal games/moves\")\n",
    "    \n",
    "    df_elo_withillegal = df_l.query(f\"(white == '{model_gpt_name}' or black == '{model_gpt_name}')\")\n",
    "    s, t = compute_score(df_elo_withillegal, model_gpt_name, percentage=False)\n",
    "    sc = s / len(df_elo_withillegal)\n",
    "    fide_elo_with_illegal_value = round(fide_elo_computation(df_elo_withillegal, model_gpt_name, sc), 0)\n",
    "    print(f\"{fide_elo_with_illegal_value} Elo for {model_gpt_name} against SF and with all games\")\n",
    "\n",
    "# Usage:\n",
    "compute_elo(df_non_random, 'gpt-3.5-turbo-instruct')\n",
    "compute_elo(df_non_random, 'gpt-4')\n",
    "\n",
    "print(\"With temperature=0\")\n",
    "df_non_random['temperature'] = df_non_random['temperature'].astype(float)\n",
    "compute_elo(df_non_random.query(\"temperature == 0.0\"), 'gpt-3.5-turbo-instruct')\n",
    "print(\"With temperature=0.8\")\n",
    "compute_elo(df_non_random.query(\"temperature != 0\"), 'gpt-3.5-turbo-instruct')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f697b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.292494300Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Elo with altered prompt\")\n",
    "compute_elo(df_non_random.query(\"pgn_base.str.contains('Rennes FRA')\"), 'gpt-3.5-turbo-instruct')\n",
    "# compute_elo(df_non_random.query(\"pgn_base.str.contains('Rennes FRA')\").query(\"temperature == 0.0\"), 'gpt-3.5-turbo-instruct')\n",
    "print(\"we don't have interactions temperature/altered prompt\")\n",
    "# compute_elo(df_non_random.query(\"pgn_base.str.contains('Rennes FRA')\").query(\"temperature == 0.8\"), 'gpt-3.5-turbo-instruct')\n",
    "\n",
    "print(\"Elo with non altered prompt\")\n",
    "compute_elo(df_non_random.query(\"not pgn_base.str.contains('Rennes FRA')\"), 'gpt-3.5-turbo-instruct')\n",
    "print(\"Elo with non altered prompt, t=0\")\n",
    "compute_elo(df_non_random.query(\"not pgn_base.str.contains('Rennes FRA')\").query(\"temperature == 0.0\"), 'gpt-3.5-turbo-instruct')\n",
    "print(\"Elo with non altered prompt, t=0.8\")\n",
    "compute_elo(df_non_random.query(\"not pgn_base.str.contains('Rennes FRA')\").query(\"temperature == 0.8\"), 'gpt-3.5-turbo-instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b23fa17",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.293632600Z"
    }
   },
   "outputs": [],
   "source": [
    "df_elo_onlywhite = df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct') and `has_illegal` == False\")\n",
    "print(round(fide_elo_computation(df_elo_onlywhite, 'gpt-3.5-turbo-instruct'), 0), \"Elo for gpt-3.5-turbo-instruct against SF and only with legal games/moves and only with white pieces\")\n",
    "\n",
    "df_elo_onlywhite_withillegal = df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct')\")\n",
    "mname = 'gpt-3.5-turbo-instruct'\n",
    "s, t = compute_score(df_elo_onlywhite_withillegal, mname, percentage=False)\n",
    "sc = s / len(df_elo_onlywhite_withillegal)\n",
    "print(round(fide_elo_computation(df_elo_onlywhite_withillegal, mname, sc), 0), \"Elo for\", mname, \"against SF and with all games and only with white pieces\")\n",
    "\n",
    "# only black\n",
    "df_elo_onlyblack_withillegal = df_non_random.query(\"(black == 'gpt-3.5-turbo-instruct')\")\n",
    "mname = 'gpt-3.5-turbo-instruct'\n",
    "s, t = compute_score(df_elo_onlyblack_withillegal, mname, percentage=False)\n",
    "sc = s / len(df_elo_onlyblack_withillegal)\n",
    "print(round(fide_elo_computation(df_elo_onlyblack_withillegal, mname, sc), 0), \"Elo for\", mname, \"against SF and with all games and only with black pieces\")\n",
    "\n",
    "# only black\n",
    "df_elo_onlyblack = df_non_random.query(\"(black == 'gpt-3.5-turbo-instruct') and `has_illegal` == False\")\n",
    "print(round(fide_elo_computation(df_elo_onlyblack, 'gpt-3.5-turbo-instruct'), 0), \"Elo for gpt-3.5-turbo-instruct against SF and only with legal games/moves and only with black pieces\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c01b2e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.298652200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_elo_ratings(df_l, model_gpt_name):\n",
    "    wrs = [] # winning games \n",
    "    lrs = [] # losing games\n",
    "    drs = [] # drawing games\n",
    "    \n",
    "    # Filter and iterate over the dataframe\n",
    "    for _, row in df_l.query(f\"(white == '{model_gpt_name}' or black == '{model_gpt_name}') and `has_illegal` == False\").iterrows():\n",
    "        if row['white'] == model_gpt_name and row['result'] == '1-0':\n",
    "            wrs.append(row['black_elo'])\n",
    "        elif row['black'] == model_gpt_name and row['result'] == '0-1':\n",
    "            wrs.append(row['white_elo'])\n",
    "        elif row['black'] == model_gpt_name and row['result'] == '1-0':\n",
    "            lrs.append(row['white_elo'])\n",
    "        elif row['white'] == model_gpt_name and row['result'] == '0-1':\n",
    "            lrs.append(row['black_elo'])\n",
    "        elif row['result'] == '1/2-1/2':\n",
    "            if row['white'] == model_gpt_name:\n",
    "                drs.append(row['black_elo'])\n",
    "            else:\n",
    "                drs.append(row['white_elo'])\n",
    "        else:\n",
    "            print(\"warning\")\n",
    "            print(row)\n",
    "            continue\n",
    "\n",
    "    wrs = [float(val) for val in wrs]\n",
    "    lrs = [float(val) for val in lrs]\n",
    "    drs = [float(val) for val in drs]\n",
    "    \n",
    "    return wrs, lrs, drs\n",
    "\n",
    "def plot_elo_distribution(wrs, lrs, drs, model_gpt_name):\n",
    "    # Compute unique Elos and their counts\n",
    "    unique_elos = sorted(np.unique(wrs))\n",
    "    win_counts = [wrs.count(elo) for elo in unique_elos]\n",
    "    draw_counts = [drs.count(elo) for elo in unique_elos]\n",
    "    lose_counts = [lrs.count(elo) for elo in unique_elos]\n",
    "\n",
    "    # Plotting\n",
    "    bar_width = 0.3\n",
    "    index = np.arange(len(unique_elos))\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.bar(index, win_counts, bar_width, alpha=0.7, color='green', label='Winning Games')\n",
    "    plt.bar(index + bar_width, draw_counts, bar_width, alpha=0.7, color='blue', label='Drawing Games')\n",
    "    plt.bar(index + 2 * bar_width, lose_counts, bar_width, alpha=0.7, color='red', label='Losing Games')\n",
    "\n",
    "    plt.xlabel('Elo Rating')\n",
    "    plt.ylabel('Number of Games')\n",
    "    plt.title(f'Distribution of Elo Ratings by Game Result for {model_gpt_name}')\n",
    "\n",
    "    plt.xticks(index + bar_width, unique_elos, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.savefig(f\"elo_distribution-scores-{model_gpt_name}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "def analyze_and_plot_elo_distribution(df_l, model_gpt_name):\n",
    "    wrs, lrs, drs = extract_elo_ratings(df_l, model_gpt_name)\n",
    "    plot_elo_distribution(wrs, lrs, drs, model_gpt_name)\n",
    "\n",
    "\n",
    "\n",
    "# Return the functions for further use\n",
    "analyze_and_plot_elo_distribution(df_non_random, \"gpt-3.5-turbo-instruct\")\n",
    "analyze_and_plot_elo_distribution(df_non_random, \"gpt-4\")\n",
    "# df_non_random\n",
    "\n",
    "\n",
    "analyze_and_plot_elo_distribution(df_non_random.query(\"not pgn_base.str.contains('Rennes FRA')\"), 'gpt-3.5-turbo-instruct')\n",
    "analyze_and_plot_elo_distribution(df_non_random.query(\"pgn_base.str.contains('Rennes FRA')\"), 'gpt-3.5-turbo-instruct')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bfc171",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.301262100Z"
    }
   },
   "outputs": [],
   "source": [
    "final_elo = fide_elo_computation(df.query('nstarting_move <= 2 and temperature == 0.0'), 'gpt-3.5-turbo-instruct') # starting_elo=1700, K=40)\n",
    "print(f\"Final Elo of gpt-3.5-turbo-instruct with white: {final_elo}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17adf86",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.302460300Z"
    }
   },
   "outputs": [],
   "source": [
    "for k, v in df_non_random.query(\"(white == 'gpt-3.5-turbo-instruct' or black == 'gpt-3.5-turbo-instruct') and `has_illegal` == False\").iterrows():\n",
    "    if v['white'] == \"gpt-3.5-turbo-instruct\" and v['black_elo'] != '?':\n",
    "            opponent_elo = float(v['black_elo'])\n",
    "    elif v['black'] == \"gpt-3.5-turbo-instruct\" and v['white_elo'] != '?':\n",
    "        opponent_elo = float(v['white_elo'])\n",
    "    else:\n",
    "        print(\"warning: no elo found for opponent\", k, v['folder_name'])\n",
    "        continue\n",
    "    result = v['result']\n",
    "    if result == '*':\n",
    "        print(\"warning: no result found for opponent\", k, v['folder_name'])\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e78377",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.304540Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df.query('nstarting_move > 2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23faccf9",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.305928900Z"
    }
   },
   "outputs": [],
   "source": [
    "df.query('nstarting_move > 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce4efc3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.310533700Z"
    }
   },
   "outputs": [],
   "source": [
    "df['has_illegal'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922ffd8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.311725Z"
    }
   },
   "outputs": [],
   "source": [
    "df['illegal_move'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa9ed56",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.314634Z"
    }
   },
   "outputs": [],
   "source": [
    "df['base_pgn_prompt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861eb3f7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.316270400Z"
    }
   },
   "outputs": [],
   "source": [
    "computation_Elo(df.query('base_pgn_prompt == False'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c76112",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.317987200Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c9e45",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.321343400Z"
    }
   },
   "outputs": [],
   "source": [
    "df.query(\"(white == 'gpt-4' or black == 'gpt-4')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edac6af4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.323296900Z"
    }
   },
   "outputs": [],
   "source": [
    "df.query(\"(white == 'gpt-3.5-turbo' or black == 'gpt-3.5-turbo')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04183c78",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-25T08:11:27.323296900Z"
    }
   },
   "outputs": [],
   "source": [
    "computation_Elo(df.query(\"(white == 'gpt-4' or black == 'gpt-4') and has_illegal == False\"), model_name='gpt-4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
